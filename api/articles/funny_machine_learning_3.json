{"title":"《机器学习有意思！ 03》- 深度学习与卷积神经网络","slug":"funny_machine_learning_3","date":"2018-01-13T04:11:00.000Z","updated":"2022-10-19T14:40:00.250Z","comments":true,"path":"api/articles/funny_machine_learning_3.json","realPath":"/2018/funny_machine_learning_3/index/","excerpt":null,"covers":["/img/funny_machine/10030.png","/img/funny_machine/10031.png","/img/funny_machine/10032.jpeg","/img/funny_machine/10030.gif","/img/funny_machine/10032.png","/img/funny_machine/10033.png","/img/funny_machine/10030.jpeg","/img/funny_machine/10034.png","/img/funny_machine/10035.png","/img/funny_machine/10031.gif","/img/funny_machine/10036.png","/img/funny_machine/10037.png","/img/funny_machine/10031.jpeg","/img/funny_machine/10038.png","/img/funny_machine/10039.png","/img/funny_machine/10040.png","/img/funny_machine/10041.png","/img/funny_machine/10042.png","/img/funny_machine/10043.png","/img/funny_machine/10044.png","/img/funny_machine/10045.png","/img/funny_machine/10046.png","/img/funny_machine/10047.png","/img/funny_machine/10048.png","/img/funny_machine/10049.png","/img/funny_machine/10050.png","/img/funny_machine/10051.png","/img/funny_machine/10052.png"],"cover":"/img/funny_machine/10030.png","content":"<h1 id=\"《机器学习有意思！-03》-深度学习与卷积神经网络\"><a href=\"#《机器学习有意思！-03》-深度学习与卷积神经网络\" class=\"headerlink\" title=\"《机器学习有意思！ 03》- 深度学习与卷积神经网络\"></a>《机器学习有意思！ 03》- 深度学习与卷积神经网络</h1><blockquote>\n<p> <em>原文：<a href=\"https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.8owg5e1ri\">Machine Learning is Fun! Part 3 – Deep Learning and Convolutional Neural Networks</a></em><br> <em>作者：Adam Geitgey</em></p>\n</blockquote>\n<hr>\n<p>你是否厌倦了每天被深度学习相关的新闻轰炸却不明所以？此诚求变之机。</p>\n<p>这一次我们将学习如何用深度学习来写程序识别图像中的物体。也可以说我们是要解释Google图片搜索背后的黑科技：Google可以通过描述搜索图片——即使图片没有事先打上标签！这是如何实现的？</p>\n<p>就像<a href=\"http://blog.buerya.cn/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018-01-09-funny_machine_learning_1.html\">Part 1</a>和<a href=\"http://blog.buerya.cn/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018-01-12-funny_machine_learning_2.html\">Part 2</a>一样，本指南仍然面向所有对机器学习感兴趣却不知如何开始的朋友们。我们的目标是所有人都读得懂——因而势必无法照顾到每个细节。但那又如何呢？只要能让一位读者对ML感兴趣，那就是功德一件了！</p>\n<hr>\n<h2 id=\"深度学习识别物体\"><a href=\"#深度学习识别物体\" class=\"headerlink\" title=\"深度学习识别物体\"></a>深度学习识别物体</h2><p><img src=\"/img/funny_machine/10030.png\"></p>\n<blockquote>\n<p>产品：每当一名用户拍了照片，APP应该检测他们是否在国家公园……</p>\n</blockquote>\n<blockquote>\n<p>开发：当然了，不过是简单的GIS查询而已，给我几个小时。</p>\n</blockquote>\n<blockquote>\n<p>产品：……以及拍的是不是一只鸟。</p>\n</blockquote>\n<blockquote>\n<p>开发：那我需要一个研究小组和五年时间。</p>\n</blockquote>\n<blockquote>\n<p>旁白：在计算机科学中，有时很难解释“简单”和“根本不可能”之间的区别。</p>\n</blockquote>\n<p>你可能已经在<a href=\"https://xkcd.com/1425/\">xkcd</a>系列漫画中看到过了。</p>\n<p>这里的笑点在于，三岁小孩儿都能认出鸟的照片，但是教会计算机识别物体，已经让最优秀的计算机科学家耗费了50年。</p>\n<p>在过去的几年里，我们终于找到了物体识别的好路子，那就是深度卷积神经网络。这听起来像是从威廉·吉布森的科幻小说里捡了几个词拼起来的，不过只要分解开来细看，其原理真的很简单。</p>\n<p>开始吧——现在就写一个能认识鸟的程序！</p>\n<hr>\n<h2 id=\"始于足下\"><a href=\"#始于足下\" class=\"headerlink\" title=\"始于足下\"></a>始于足下</h2><p>在我们学习如何辨别鸟的照片之前，先来学个简单得多的例子——手写数字”8”。</p>\n<p>在Part 2中，我们已经学习了神经网络如何链接大量的神经元来解决复杂问题。我们搭建了一个迷你神经网络来基于房间数、面积、周边环境预测房价：</p>\n<p><img src=\"/img/funny_machine/10031.png\"></p>\n<p>我们还知道了机器学习的思想就是重复利用相同的普适算法，根据不同的数据，解决不同的问题。下面我们修改这个神经网络来识别手写文本，并且进一步简化任务——只识别数字”8”。</p>\n<p>机器学习只有当你有数据的时候才好使——数据越多越好，所以我们需要大量的手写”8”来开始。所幸，研究者们为了这一目的已经建立了<a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST手写数字数据集</a>。<code>MNIST</code>提供了60,000张手写数字的图片，每个尺寸都是18x18，以下是数据集里部分的”8”：</p>\n<p><img src=\"/img/funny_machine/10032.jpeg\" alt=\"MNIST数据集里的一些8\"></p>\n<p><strong>其实不过是数字</strong></p>\n<p>Part 2里搭建的神经网络只读取3个输入（”3”间卧室,”2000”平方米等）。但是现在我们要用神经网络处理图片，不是数字怎么传入神经网络呢？</p>\n<p>答案无比的简单。神经网络以数字为输入，对于计算机来说，图片也不过只是代表了像素明暗的数字：</p>\n<p><img src=\"/img/funny_machine/10030.gif\"></p>\n<p>只要把18x18像素的图片当作324个数字组成的数组，就可以把图片输入给神经网络了。</p>\n<p><img src=\"/img/funny_machine/10032.png\"></p>\n<p>要处理324个输入，我们只需让神经网络具有324个输入节点：</p>\n<p><img src=\"/img/funny_machine/10033.png\"></p>\n<p>注意我们的神经网络现在有两个输出（而非之前的一个）。第一个输出是预测此图为”8”的概率，第二个为不是”8”的概率。每种类型的目标物体有了分别的输出，就可以让神经网络对物体进行分类了。</p>\n<p>这次的神经网络比之前要大得多了（从3个输入到324），但是现代的计算机处理几百个节点的神经网络，连眼都不带眨的，甚至连手机都能轻松满足。</p>\n<p>剩下的就是用”8”和非”8”的数字去训练神经网络以使其能够区分两者了，当我们输入一个”8”，我们告诉神经网络，此图为”8”的概率是100%，非”8”的概率是0%，反之亦反。</p>\n<p>这是我们的训练数据：</p>\n<p><img src=\"/img/funny_machine/10030.jpeg\"></p>\n<p>现在随便一个笔记本电脑，也能在几分钟之内训练完这样一个网络，训练完之后我们就拥有了能够高精度识别数字”8”的神经网络。欢迎来到（1980年代的）图像识别世界！</p>\n<hr>\n<h2 id=\"管窥\"><a href=\"#管窥\" class=\"headerlink\" title=\"管窥\"></a>管窥</h2><p>把像素简单地导入神经网络里一训练，就能识别图像了，感觉无比清爽。机器学习真乃魔法……也？</p>\n<p><em>事情并不简单。</em></p>\n<p>首先，一个好消息是，我们的识8器对于图片正中的数字，效果还是很喜人的：</p>\n<p><img src=\"/img/funny_machine/10034.png\"></p>\n<p>现在坏消息来了：</p>\n<p>当数字不是恰好居中的时候，识8器完全失效了，哪怕一丁点的位置偏差也不行：</p>\n<p><img src=\"/img/funny_machine/10035.png\"></p>\n<p>这是因为，神经网络只学到了恰好居中”8”的模式，但是对于离心的”8”却一无所知，它知道且仅知道一种模式。</p>\n<p>在现实中这就实用价值不大了，因为实际问题不可能总是那么干净简约。所以我们必须让神经网络能够处理离心的”8”。</p>\n<h3 id=\"暴力方法-1-滑动窗口搜索\"><a href=\"#暴力方法-1-滑动窗口搜索\" class=\"headerlink\" title=\"暴力方法 1. 滑动窗口搜索\"></a>暴力方法 1. 滑动窗口搜索</h3><p>我们已经有了一个好方法，能够找到图片中心的”8”，那可不可以在图片上扫描寻找子区域里的”8”，直至找到呢？</p>\n<p><img src=\"/img/funny_machine/10031.gif\"></p>\n<p>这就是滑动窗口法，一种非常暴力的解决方案。在很有限的某些例子中可行，但效率也很低。你必须一遍一遍地寻找不同尺寸的物体，我们可以比这更好。</p>\n<h3 id=\"暴力方法-2-更多数据，更深网络\"><a href=\"#暴力方法-2-更多数据，更深网络\" class=\"headerlink\" title=\"暴力方法 2. 更多数据，更深网络\"></a>暴力方法 2. 更多数据，更深网络</h3><p>当我们在训练网络的时候，只用到了完美居中的”8”。如果我们在训练过程中就引入不同位置、不同大小的”8”，那会怎么样呢？</p>\n<p>不需要收集更多的训练数据，我们可以写个脚本生成新的图片，图中的”8”具有不同的位置和大小：</p>\n<p><img src=\"/img/funny_machine/10036.png\" alt=\"用已有训练图片的不同视角制成的合成训练数据，这是个挺有用的技术\"></p>\n<p>应用这一技术，我们可以轻易创造出无穷多的训练数据。</p>\n<p>更多的数据让问题变得更加复杂了，但是我们可以用更大的神经网络，那样就能学习更复杂的模式。为了扩大网络，我们简单地把节点层堆叠起来：</p>\n<p><img src=\"/img/funny_machine/10037.png\"></p>\n<p>这就是“深度神经网络”，因为比传统神经网络的层数更多。这个想法在1960年代便有了，不过直至最近，训练这么大的神经网络训练还是慢得无法接受。但是自从我们发现了用3d显卡替代传统CPU来加速矩阵计算，大规模神经网络就变得可行了。你用来玩守望先锋的NVIDIA GeForce GTX 1080显卡，也可以用来训练神经网络。</p>\n<p>然而即便我们可以用显卡很快地训练出大规模神经网络，这仍然不是解决方案的全部，我们还需要在处理图片上更加机智才行。</p>\n<p>在暴力方法2中，把图片顶端的”8”和图片底部的”8”当作完全不同的物体，这其实是没有意义的。应该存在一种方案，让神经网络不经额外训练即知：图片不管哪个位置的”8”都是一个东西。万幸，确实是存在的！</p>\n<hr>\n<h2 id=\"答案：卷积\"><a href=\"#答案：卷积\" class=\"headerlink\" title=\"答案：卷积\"></a>答案：卷积</h2><p>生而为人，你可以直观地看出照片中含有层次或概念结构。考虑这张照片：</p>\n<p><img src=\"/img/funny_machine/10031.jpeg\" alt=\"作者儿子的照片\"></p>\n<p>作为一个人类，你立即就能识别出照片里的层次：</p>\n<ul>\n<li><p>地面覆盖了草坪</p>\n</li>\n<li><p>图里有个小孩儿</p>\n</li>\n<li><p>小孩儿骑在弹跳小马上</p>\n</li>\n<li><p>弹跳小马在草坪上</p>\n</li>\n</ul>\n<p>更重要的是，无论小孩在什么样的表面上，我们都能认出那是个小孩儿。我们并不需要重新学习各种表面上的小孩儿。但是目前，神经网络还做不到这些，它会把不同位置的”8”当作完全不同的东西，而并不知道在图片上移动物体不会改变其实质。这意味着网络必须重新学习每个位置上的物体，太悲催了。</p>\n<p>我们需要让神经网络明白平移不变形——“8”还是”8”，不论出现在图片的哪里。这一过程可由卷积实现，卷积的想法部分来自计算机科学，还有部分是受生物学启发（比如，疯狂科学家们真的在猫脑子里插管，以研究猫是怎么处理图像的人）。</p>\n<hr>\n<h2 id=\"卷积的作用机理\"><a href=\"#卷积的作用机理\" class=\"headerlink\" title=\"卷积的作用机理\"></a>卷积的作用机理</h2><p>这次我们不再把整个图片当成一个数字网格输入到神经网络，而是利用物体与位置的独立性，做得更聪明些。以下就是卷积的作用机理，一步一步来——</p>\n<p><strong>第1步：把图片分解为重叠碎片</strong></p>\n<p>与之前的滑动窗口法类似，这里也用一个窗口在整张原图上滑动截图，并且把截到的每一小部分单独存成一个图片：</p>\n<p><img src=\"/img/funny_machine/10038.png\"></p>\n<p>如此我们便把一张大图拆成了77张等尺寸的小图。</p>\n<p><strong>第2步：把每张小图输入小神经网络</strong></p>\n<p>曾经我们把单张图片输入神经网络来判断其是否为”8”，这里再重复一样的工作，不过是针对每一个单独的小图片：</p>\n<p><img src=\"/img/funny_machine/10039.png\" alt=\"对每个小图片重复77次\"></p>\n<p>这里还有一大诀窍：我们将相同的<em>神经网络权重</em>应用在每一块小图上。换言之，我们平等地对待所有小图，如果某个小图里出现了我们感兴趣的内容，我们就将其标记为有趣。</p>\n<p><strong>第3步：把每块小图的结果存入新的阵列</strong></p>\n<p>我们并不想丢失原始小图的排列信息，所以我们要把每个小图的结果按照相同的排列重新构建原图，形式如下：</p>\n<p><img src=\"/img/funny_machine/10040.png\"></p>\n<p>也可以说，我们从一张大图片开始，到小阵列结束，阵列记录了原图当中哪一部分有我们最关心的内容。</p>\n<p><strong>第4步：下采样</strong></p>\n<p>第3步的结果是一个阵列，反映了原图的哪一部分是我们最感兴趣的，不过这个阵列仍然很庞大：</p>\n<p><img src=\"/img/funny_machine/10041.png\"></p>\n<p>为了减小阵列的尺寸，我们用<a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer\">最大池化</a>算法进行下采样。听着很稀奇，其实完全不！</p>\n<p>看阵列中的每个2x2方块，并且只留下最大的数字：</p>\n<p><img src=\"/img/funny_machine/10042.png\"></p>\n<p>这里的主要思路就是，当我们在组成2x2方块的四个输入小图中的任意一个发现了关心的内容，就只保留我们最感兴趣的信息，这可以减小阵列规模并保留最重要的信息。</p>\n<p><strong>最终步：预测</strong></p>\n<p>至此，我们已经把一个巨大的图片消减成了相对较小的阵列，阵列就是一串数，所以我们可以把小阵列输入另一个神经网络，最后的这个神经网络会决定图片是否匹配。为了与卷积层相区分，我们称之为“全连接层”。从头到尾，我们的五步流水线如下图所示：</p>\n<p><img src=\"/img/funny_machine/10043.png\"></p>\n<p><strong>增加更多步骤</strong></p>\n<p>我们的图像处理流水线有一系列步骤：卷积，最大池化，全连接网络。</p>\n<p>而在解决实际问题的时候，这些步骤可以组合起来并堆叠多次。你可以加两个，三个甚至十个卷积层，也可以在任何时候插入一个最大池化层。总之基本思路就是把一张大图，逐步分解为小图，直至我们能够获得结果。卷积层越多，网络就能学习识别越复杂的特征。</p>\n<p>比如说，第一个卷积层可能学会了辨认锐利边缘，第二个卷积层可能根据锐边的知识学会了识别鸟喙，第三个卷积层又基于鸟喙识别出了整只鸟。以下是更贴近实践的深度卷积网络结构（学术论文里常见）：</p>\n<p><img src=\"/img/funny_machine/10044.png\"></p>\n<p>在这一实例中，他们从224x224像素的图片开始，应用了：卷积，两次最大池化，三次卷积，又是两次最大池化，最后是两个全连接层。最终的结果可以将图片从1000个分类中识别出来。</p>\n<p><strong>构建正确的网络</strong></p>\n<p>那么我们要怎么知道什么时候该用什么层呢？诚然，你得经过大量的实践和测试才能回答，可能训练100个网络才能找到最佳的结构和参数。机器学习就是包含了大量的尝试和错误！</p>\n<h2 id=\"构建鸟分类器\"><a href=\"#构建鸟分类器\" class=\"headerlink\" title=\"构建鸟分类器\"></a>构建鸟分类器</h2><p>如今我们已经足以写出一个程序来判断一张图上是不是鸟类。一如既往，我们需要训练数据来开始。免费的<a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR10数据集</a>包括了60,000张鸟类图片和52,000张非鸟图片。如果要更多的数据，我们还需要加入<a href=\"http://www.vision.caltech.edu/visipedia/CUB-200-2011.html\">Caltech-UCSD Birds-200-2011</a>数据集，内含12,000张鸟类图片。</p>\n<p>这是组合数据集的一部分鸟图：</p>\n<p><img src=\"/img/funny_machine/10045.png\"></p>\n<p>以及一部分非鸟图：</p>\n<p><img src=\"/img/funny_machine/10046.png\"></p>\n<p>这一数据集可以很好地满足我们的需求，不过相对于真实世界的应用而言，72,000张低分辨率图片还是太少，如果你想要达到Google级的水平，你需要上百万张高清无码大图。在机器学习中，数据多总是比算法好更重要。现在你就知道Google为什么那么乐意提供无限照片存储了，他们要的是你的数据啊，数据！</p>\n<blockquote>\n<p>原作者使用的是TFLearn，译注者改用了国内更流行的Keras。TFLearn代码可见作者原文。</p>\n</blockquote>\n<p>Keras封装了TensorFlow和Theano两个深度学习库并提供了简单易用的API，这使得开发者可以仅用几行就搭建一个卷积神经网络。</p>\n<p>以下是定义并训练网络的代码：</p>\n<p><strong>导入数据</strong></p>\n<p>Keras内置了CIFAR10数据集，但是需要从网络上下载。</p>\n<p>Keras导入CIFAR10数据集:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入相关库</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.misc <span class=\"keyword\">import</span> toimage</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.models <span class=\"keyword\">import</span> Sequential</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dense</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dropout</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Flatten</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.constraints <span class=\"keyword\">import</span> maxnorm</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.optimizers <span class=\"keyword\">import</span> SGD</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers.convolutional <span class=\"keyword\">import</span> Convolution2D</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers.convolutional <span class=\"keyword\">import</span> MaxPooling2D</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.utils <span class=\"keyword\">import</span> np_utils</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> backend <span class=\"keyword\">as</span> K</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义训练集、测试集</span></span><br><span class=\"line\">(X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Datasets is ready!&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预览部分图片</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">9</span>):</span><br><span class=\"line\">    pyplot.subplot(<span class=\"number\">330</span> + <span class=\"number\">1</span> + i)</span><br><span class=\"line\">    pyplot.imshow(toimage(X_train[i]))</span><br><span class=\"line\"></span><br><span class=\"line\">pyplot.show()</span><br></pre></td></tr></table></figure>\n\n<p><strong>搭建神经网络</strong></p>\n<p>下面导入其他将会用到的Keras相关模块并对数据进行预处理。Keras搭建神经网络的过程其实非常简单直观，就像搭积木一样。</p>\n<p>首先确定网络的基本结构，这里就用最基本<code>Sequential()</code>串型拓扑，并建立网络模型对象<code>model</code>。</p>\n<p>之后便是给<code>model</code>中一层层地添加网络，添加的方式也很简单，就是使用<code>model.add()</code>方法，逐个地把卷积层(<code>Convolution2D</code>)、池化层(<code>MaxPooling2D</code>)、全连接层(<code>Dense</code>)等插入到model里，形成整个神经网络。</p>\n<p>Keras搭建神经网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 对标签进行独热码编码</span></span><br><span class=\"line\">y_train = np_utils.to_categorical(y_train)</span><br><span class=\"line\">y_test = np_utils.to_categorical(y_test)</span><br><span class=\"line\">num_classes = y_test.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置神经网络对象model</span></span><br><span class=\"line\">model = Sequential()</span><br><span class=\"line\">model.add(Convolution2D(<span class=\"number\">32</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>,input_shape=(<span class=\"number\">32</span>,<span class=\"number\">32</span>,<span class=\"number\">3</span>),</span><br><span class=\"line\">                        border_mode=<span class=\"string\">&#x27;same&#x27;</span>,activation=<span class=\"string\">&#x27;relu&#x27;</span>,</span><br><span class=\"line\">                        W_constraint=maxnorm(<span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(Dropout(<span class=\"number\">0.2</span>))</span><br><span class=\"line\">model.add(Convolution2D(<span class=\"number\">32</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>,activation=<span class=\"string\">&#x27;relu&#x27;</span>,</span><br><span class=\"line\">                    border_mode=<span class=\"string\">&#x27;same&#x27;</span>,W_constraint=maxnorm(<span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(MaxPooling2D(pool_size=(<span class=\"number\">2</span>,<span class=\"number\">2</span>)))</span><br><span class=\"line\">model.add(Flatten())</span><br><span class=\"line\">model.add(Dense(<span class=\"number\">512</span>,activation=<span class=\"string\">&#x27;relu&#x27;</span>,W_constraint=maxnorm(<span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(Dropout(<span class=\"number\">0.5</span>))</span><br><span class=\"line\">model.add(Dense(num_classes,activation=<span class=\"string\">&#x27;softmax&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Neural Network built!&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>编译、训练、预测</strong></p>\n<p>经过以上过程，我们已经有了一个神经网络的外壳，但也仅仅是外壳，你会注意到上面这个代码模块运行的很快，因为这只是根据神经网络的设置形成了一个容器，内部还是空空如也。还要经过“编译”并且导入数据进行“训练”，我们才真正拥有了“有血有肉”的神经网络。最后通过与测试集的对比，衡量神经网络的表现。</p>\n<p>虽然数据量并不大，但是训练神经网络对于普通CPU来说，还是个比较艰巨的任务，因此训练速度可能堪忧。我们的网站后台暂时还未提供GPU接口，所以这里只能先将训练迭代次数设为1，以后我们会争取提供更强大的计算资源。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 设定训练过程</span></span><br><span class=\"line\">epoches = <span class=\"number\">1</span>  <span class=\"comment\"># 对训练集的迭代次数（这里设为最小的1）</span></span><br><span class=\"line\">lrate = <span class=\"number\">0.01</span> <span class=\"comment\"># 初始学习率</span></span><br><span class=\"line\">decay = lrate/epoches</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 优化器设置与编译</span></span><br><span class=\"line\">sgd = SGD(lr=lrate, momentum=<span class=\"number\">0.9</span>, decay=decay, nesterov=<span class=\"literal\">False</span>)</span><br><span class=\"line\">model.<span class=\"built_in\">compile</span>(loss=<span class=\"string\">&#x27;categorical_crossentropy&#x27;</span>,optimizer=sgd,metrics=[<span class=\"string\">&#x27;accuracy&#x27;</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.summary())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用训练集数据训练网络</span></span><br><span class=\"line\">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epoches,</span><br><span class=\"line\">          batch_size=<span class=\"number\">32</span>, verbose=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出神经网络的表现</span></span><br><span class=\"line\">scores = model.evaluate(X_test, y_test, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Accuracy: %.2f%%&quot;</span>) % (scores[<span class=\"number\">1</span>]*<span class=\"number\">100</span>)</span><br></pre></td></tr></table></figure>\n\n<p>如果你有个不错的显卡和足够的显存（比如Nvidia GeForce GTX 980 Ti或以上），大概一个小时可以训练完，如果用CPU的话可能就要久的多了。</p>\n<p>精度随着训练进程儿上升。第一轮过后，我的精度只有75.4%；经过十轮，精度已经提高到91.7%；在50轮以后，精度攀升到95.5%，再训练已经收效甚微了，因此我就此打住。</p>\n<p>Congrats!现在我们的程序可以识别图片里的鸟了！</p>\n<hr>\n<h2 id=\"测试网络\"><a href=\"#测试网络\" class=\"headerlink\" title=\"测试网络\"></a>测试网络</h2><p>有了训练过的神经网络，是骡子是马该拉出来遛遛。<a href=\"https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0\">这一简单的脚本</a>读取一个图片文件并判断是否是鸟。</p>\n<p>为了真正检验我们的神经网络是否有效，需要测试大批的图片。我这里用了15,000张图片作为验证集，当我把这15,000张图传递给神经网络，95%都得到了正确答案。</p>\n<p>听起来很好，对吧？其实这可未必！</p>\n<p><strong>95%是多准确？</strong></p>\n<p>我们的神经网络号称有95%的准确度，但是细微之处见真章，面子上95%，里子可能千差万别。比如说，如果我们的训练图片里5%是鸟，而另外95%不是鸟，然后一个程序只输出“不是鸟”就可以达到95%的精度，但这毫无意义。</p>\n<p>我们需要进一步细究这个数字，而不是满足于一个含糊的95%。为了判断一个分类系统的作用究竟几何，我们需要考察它是如何失效的，而不是失效的百分比。抛掉单纯的“对／错”标准，我们来把问题细分为四种分别的情况——</p>\n<ol>\n<li>把鸟正确地识别为鸟：<strong>True Positives</strong></li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10047.png\" alt=\"我们的网络成功地认出了很多不同的鸟类！\"></p>\n<ol start=\"2\">\n<li>把不是鸟的正确地排除出去：<strong>True Negatives</strong></li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10048.png\" alt=\"马和卡车糊弄不了我们\"></p>\n<ol start=\"3\">\n<li>以为是鸟，结果不是：<strong>False Positives</strong>（错杀三千）</li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10049.png\" alt=\"有些飞机也被当成鸟了\"></p>\n<ol start=\"4\">\n<li>其实是鸟，以为不是：<strong>False Negative</strong>（放过一个）</li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10050.png\" alt=\"这些鸟把我们糊弄了\"></p>\n<p>根据我们这15,000张图片，以下为各种情况的统计数据：</p>\n<p><img src=\"/img/funny_machine/10051.png\"></p>\n<p>为什么要这样细分结果呢？因为并非每种错误都是均等的。想象一下，如果我们在写一个根据MRI图像诊断癌症的程序，这时候宁可引入<strong>False Positive</strong>也不要带有<strong>False Negative</strong>。前者只是让患者虚惊一场，后者可就是延误治疗了。</p>\n<p>所以出了宽泛的准确度，我们还计算<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">精确率和召回率</a>。精确率和召回率更加清晰地定义了分类起的效用。</p>\n<p><img src=\"/img/funny_machine/10052.png\"></p>\n<p>由上表可知，当我们给出“是鸟”的猜测时，其中97%是对的。但是我们却只找出了90%的鸟，这意味着我们可能不是所有鸟都认得，但是认鸟却很准！</p>\n","more":"<h1 id=\"《机器学习有意思！-03》-深度学习与卷积神经网络\"><a href=\"#《机器学习有意思！-03》-深度学习与卷积神经网络\" class=\"headerlink\" title=\"《机器学习有意思！ 03》- 深度学习与卷积神经网络\"></a>《机器学习有意思！ 03》- 深度学习与卷积神经网络</h1><blockquote>\n<p> <em>原文：<a href=\"https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.8owg5e1ri\">Machine Learning is Fun! Part 3 – Deep Learning and Convolutional Neural Networks</a></em><br> <em>作者：Adam Geitgey</em></p>\n</blockquote>\n<hr>\n<p>你是否厌倦了每天被深度学习相关的新闻轰炸却不明所以？此诚求变之机。</p>\n<p>这一次我们将学习如何用深度学习来写程序识别图像中的物体。也可以说我们是要解释Google图片搜索背后的黑科技：Google可以通过描述搜索图片——即使图片没有事先打上标签！这是如何实现的？</p>\n<p>就像<a href=\"http://blog.buerya.cn/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018-01-09-funny_machine_learning_1.html\">Part 1</a>和<a href=\"http://blog.buerya.cn/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018-01-12-funny_machine_learning_2.html\">Part 2</a>一样，本指南仍然面向所有对机器学习感兴趣却不知如何开始的朋友们。我们的目标是所有人都读得懂——因而势必无法照顾到每个细节。但那又如何呢？只要能让一位读者对ML感兴趣，那就是功德一件了！</p>\n<hr>\n<h2 id=\"深度学习识别物体\"><a href=\"#深度学习识别物体\" class=\"headerlink\" title=\"深度学习识别物体\"></a>深度学习识别物体</h2><p><img src=\"/img/funny_machine/10030.png\"></p>\n<blockquote>\n<p>产品：每当一名用户拍了照片，APP应该检测他们是否在国家公园……</p>\n</blockquote>\n<blockquote>\n<p>开发：当然了，不过是简单的GIS查询而已，给我几个小时。</p>\n</blockquote>\n<blockquote>\n<p>产品：……以及拍的是不是一只鸟。</p>\n</blockquote>\n<blockquote>\n<p>开发：那我需要一个研究小组和五年时间。</p>\n</blockquote>\n<blockquote>\n<p>旁白：在计算机科学中，有时很难解释“简单”和“根本不可能”之间的区别。</p>\n</blockquote>\n<p>你可能已经在<a href=\"https://xkcd.com/1425/\">xkcd</a>系列漫画中看到过了。</p>\n<p>这里的笑点在于，三岁小孩儿都能认出鸟的照片，但是教会计算机识别物体，已经让最优秀的计算机科学家耗费了50年。</p>\n<p>在过去的几年里，我们终于找到了物体识别的好路子，那就是深度卷积神经网络。这听起来像是从威廉·吉布森的科幻小说里捡了几个词拼起来的，不过只要分解开来细看，其原理真的很简单。</p>\n<p>开始吧——现在就写一个能认识鸟的程序！</p>\n<hr>\n<h2 id=\"始于足下\"><a href=\"#始于足下\" class=\"headerlink\" title=\"始于足下\"></a>始于足下</h2><p>在我们学习如何辨别鸟的照片之前，先来学个简单得多的例子——手写数字”8”。</p>\n<p>在Part 2中，我们已经学习了神经网络如何链接大量的神经元来解决复杂问题。我们搭建了一个迷你神经网络来基于房间数、面积、周边环境预测房价：</p>\n<p><img src=\"/img/funny_machine/10031.png\"></p>\n<p>我们还知道了机器学习的思想就是重复利用相同的普适算法，根据不同的数据，解决不同的问题。下面我们修改这个神经网络来识别手写文本，并且进一步简化任务——只识别数字”8”。</p>\n<p>机器学习只有当你有数据的时候才好使——数据越多越好，所以我们需要大量的手写”8”来开始。所幸，研究者们为了这一目的已经建立了<a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST手写数字数据集</a>。<code>MNIST</code>提供了60,000张手写数字的图片，每个尺寸都是18x18，以下是数据集里部分的”8”：</p>\n<p><img src=\"/img/funny_machine/10032.jpeg\" alt=\"MNIST数据集里的一些8\"></p>\n<p><strong>其实不过是数字</strong></p>\n<p>Part 2里搭建的神经网络只读取3个输入（”3”间卧室,”2000”平方米等）。但是现在我们要用神经网络处理图片，不是数字怎么传入神经网络呢？</p>\n<p>答案无比的简单。神经网络以数字为输入，对于计算机来说，图片也不过只是代表了像素明暗的数字：</p>\n<p><img src=\"/img/funny_machine/10030.gif\"></p>\n<p>只要把18x18像素的图片当作324个数字组成的数组，就可以把图片输入给神经网络了。</p>\n<p><img src=\"/img/funny_machine/10032.png\"></p>\n<p>要处理324个输入，我们只需让神经网络具有324个输入节点：</p>\n<p><img src=\"/img/funny_machine/10033.png\"></p>\n<p>注意我们的神经网络现在有两个输出（而非之前的一个）。第一个输出是预测此图为”8”的概率，第二个为不是”8”的概率。每种类型的目标物体有了分别的输出，就可以让神经网络对物体进行分类了。</p>\n<p>这次的神经网络比之前要大得多了（从3个输入到324），但是现代的计算机处理几百个节点的神经网络，连眼都不带眨的，甚至连手机都能轻松满足。</p>\n<p>剩下的就是用”8”和非”8”的数字去训练神经网络以使其能够区分两者了，当我们输入一个”8”，我们告诉神经网络，此图为”8”的概率是100%，非”8”的概率是0%，反之亦反。</p>\n<p>这是我们的训练数据：</p>\n<p><img src=\"/img/funny_machine/10030.jpeg\"></p>\n<p>现在随便一个笔记本电脑，也能在几分钟之内训练完这样一个网络，训练完之后我们就拥有了能够高精度识别数字”8”的神经网络。欢迎来到（1980年代的）图像识别世界！</p>\n<hr>\n<h2 id=\"管窥\"><a href=\"#管窥\" class=\"headerlink\" title=\"管窥\"></a>管窥</h2><p>把像素简单地导入神经网络里一训练，就能识别图像了，感觉无比清爽。机器学习真乃魔法……也？</p>\n<p><em>事情并不简单。</em></p>\n<p>首先，一个好消息是，我们的识8器对于图片正中的数字，效果还是很喜人的：</p>\n<p><img src=\"/img/funny_machine/10034.png\"></p>\n<p>现在坏消息来了：</p>\n<p>当数字不是恰好居中的时候，识8器完全失效了，哪怕一丁点的位置偏差也不行：</p>\n<p><img src=\"/img/funny_machine/10035.png\"></p>\n<p>这是因为，神经网络只学到了恰好居中”8”的模式，但是对于离心的”8”却一无所知，它知道且仅知道一种模式。</p>\n<p>在现实中这就实用价值不大了，因为实际问题不可能总是那么干净简约。所以我们必须让神经网络能够处理离心的”8”。</p>\n<h3 id=\"暴力方法-1-滑动窗口搜索\"><a href=\"#暴力方法-1-滑动窗口搜索\" class=\"headerlink\" title=\"暴力方法 1. 滑动窗口搜索\"></a>暴力方法 1. 滑动窗口搜索</h3><p>我们已经有了一个好方法，能够找到图片中心的”8”，那可不可以在图片上扫描寻找子区域里的”8”，直至找到呢？</p>\n<p><img src=\"/img/funny_machine/10031.gif\"></p>\n<p>这就是滑动窗口法，一种非常暴力的解决方案。在很有限的某些例子中可行，但效率也很低。你必须一遍一遍地寻找不同尺寸的物体，我们可以比这更好。</p>\n<h3 id=\"暴力方法-2-更多数据，更深网络\"><a href=\"#暴力方法-2-更多数据，更深网络\" class=\"headerlink\" title=\"暴力方法 2. 更多数据，更深网络\"></a>暴力方法 2. 更多数据，更深网络</h3><p>当我们在训练网络的时候，只用到了完美居中的”8”。如果我们在训练过程中就引入不同位置、不同大小的”8”，那会怎么样呢？</p>\n<p>不需要收集更多的训练数据，我们可以写个脚本生成新的图片，图中的”8”具有不同的位置和大小：</p>\n<p><img src=\"/img/funny_machine/10036.png\" alt=\"用已有训练图片的不同视角制成的合成训练数据，这是个挺有用的技术\"></p>\n<p>应用这一技术，我们可以轻易创造出无穷多的训练数据。</p>\n<p>更多的数据让问题变得更加复杂了，但是我们可以用更大的神经网络，那样就能学习更复杂的模式。为了扩大网络，我们简单地把节点层堆叠起来：</p>\n<p><img src=\"/img/funny_machine/10037.png\"></p>\n<p>这就是“深度神经网络”，因为比传统神经网络的层数更多。这个想法在1960年代便有了，不过直至最近，训练这么大的神经网络训练还是慢得无法接受。但是自从我们发现了用3d显卡替代传统CPU来加速矩阵计算，大规模神经网络就变得可行了。你用来玩守望先锋的NVIDIA GeForce GTX 1080显卡，也可以用来训练神经网络。</p>\n<p>然而即便我们可以用显卡很快地训练出大规模神经网络，这仍然不是解决方案的全部，我们还需要在处理图片上更加机智才行。</p>\n<p>在暴力方法2中，把图片顶端的”8”和图片底部的”8”当作完全不同的物体，这其实是没有意义的。应该存在一种方案，让神经网络不经额外训练即知：图片不管哪个位置的”8”都是一个东西。万幸，确实是存在的！</p>\n<hr>\n<h2 id=\"答案：卷积\"><a href=\"#答案：卷积\" class=\"headerlink\" title=\"答案：卷积\"></a>答案：卷积</h2><p>生而为人，你可以直观地看出照片中含有层次或概念结构。考虑这张照片：</p>\n<p><img src=\"/img/funny_machine/10031.jpeg\" alt=\"作者儿子的照片\"></p>\n<p>作为一个人类，你立即就能识别出照片里的层次：</p>\n<ul>\n<li><p>地面覆盖了草坪</p>\n</li>\n<li><p>图里有个小孩儿</p>\n</li>\n<li><p>小孩儿骑在弹跳小马上</p>\n</li>\n<li><p>弹跳小马在草坪上</p>\n</li>\n</ul>\n<p>更重要的是，无论小孩在什么样的表面上，我们都能认出那是个小孩儿。我们并不需要重新学习各种表面上的小孩儿。但是目前，神经网络还做不到这些，它会把不同位置的”8”当作完全不同的东西，而并不知道在图片上移动物体不会改变其实质。这意味着网络必须重新学习每个位置上的物体，太悲催了。</p>\n<p>我们需要让神经网络明白平移不变形——“8”还是”8”，不论出现在图片的哪里。这一过程可由卷积实现，卷积的想法部分来自计算机科学，还有部分是受生物学启发（比如，疯狂科学家们真的在猫脑子里插管，以研究猫是怎么处理图像的人）。</p>\n<hr>\n<h2 id=\"卷积的作用机理\"><a href=\"#卷积的作用机理\" class=\"headerlink\" title=\"卷积的作用机理\"></a>卷积的作用机理</h2><p>这次我们不再把整个图片当成一个数字网格输入到神经网络，而是利用物体与位置的独立性，做得更聪明些。以下就是卷积的作用机理，一步一步来——</p>\n<p><strong>第1步：把图片分解为重叠碎片</strong></p>\n<p>与之前的滑动窗口法类似，这里也用一个窗口在整张原图上滑动截图，并且把截到的每一小部分单独存成一个图片：</p>\n<p><img src=\"/img/funny_machine/10038.png\"></p>\n<p>如此我们便把一张大图拆成了77张等尺寸的小图。</p>\n<p><strong>第2步：把每张小图输入小神经网络</strong></p>\n<p>曾经我们把单张图片输入神经网络来判断其是否为”8”，这里再重复一样的工作，不过是针对每一个单独的小图片：</p>\n<p><img src=\"/img/funny_machine/10039.png\" alt=\"对每个小图片重复77次\"></p>\n<p>这里还有一大诀窍：我们将相同的<em>神经网络权重</em>应用在每一块小图上。换言之，我们平等地对待所有小图，如果某个小图里出现了我们感兴趣的内容，我们就将其标记为有趣。</p>\n<p><strong>第3步：把每块小图的结果存入新的阵列</strong></p>\n<p>我们并不想丢失原始小图的排列信息，所以我们要把每个小图的结果按照相同的排列重新构建原图，形式如下：</p>\n<p><img src=\"/img/funny_machine/10040.png\"></p>\n<p>也可以说，我们从一张大图片开始，到小阵列结束，阵列记录了原图当中哪一部分有我们最关心的内容。</p>\n<p><strong>第4步：下采样</strong></p>\n<p>第3步的结果是一个阵列，反映了原图的哪一部分是我们最感兴趣的，不过这个阵列仍然很庞大：</p>\n<p><img src=\"/img/funny_machine/10041.png\"></p>\n<p>为了减小阵列的尺寸，我们用<a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer\">最大池化</a>算法进行下采样。听着很稀奇，其实完全不！</p>\n<p>看阵列中的每个2x2方块，并且只留下最大的数字：</p>\n<p><img src=\"/img/funny_machine/10042.png\"></p>\n<p>这里的主要思路就是，当我们在组成2x2方块的四个输入小图中的任意一个发现了关心的内容，就只保留我们最感兴趣的信息，这可以减小阵列规模并保留最重要的信息。</p>\n<p><strong>最终步：预测</strong></p>\n<p>至此，我们已经把一个巨大的图片消减成了相对较小的阵列，阵列就是一串数，所以我们可以把小阵列输入另一个神经网络，最后的这个神经网络会决定图片是否匹配。为了与卷积层相区分，我们称之为“全连接层”。从头到尾，我们的五步流水线如下图所示：</p>\n<p><img src=\"/img/funny_machine/10043.png\"></p>\n<p><strong>增加更多步骤</strong></p>\n<p>我们的图像处理流水线有一系列步骤：卷积，最大池化，全连接网络。</p>\n<p>而在解决实际问题的时候，这些步骤可以组合起来并堆叠多次。你可以加两个，三个甚至十个卷积层，也可以在任何时候插入一个最大池化层。总之基本思路就是把一张大图，逐步分解为小图，直至我们能够获得结果。卷积层越多，网络就能学习识别越复杂的特征。</p>\n<p>比如说，第一个卷积层可能学会了辨认锐利边缘，第二个卷积层可能根据锐边的知识学会了识别鸟喙，第三个卷积层又基于鸟喙识别出了整只鸟。以下是更贴近实践的深度卷积网络结构（学术论文里常见）：</p>\n<p><img src=\"/img/funny_machine/10044.png\"></p>\n<p>在这一实例中，他们从224x224像素的图片开始，应用了：卷积，两次最大池化，三次卷积，又是两次最大池化，最后是两个全连接层。最终的结果可以将图片从1000个分类中识别出来。</p>\n<p><strong>构建正确的网络</strong></p>\n<p>那么我们要怎么知道什么时候该用什么层呢？诚然，你得经过大量的实践和测试才能回答，可能训练100个网络才能找到最佳的结构和参数。机器学习就是包含了大量的尝试和错误！</p>\n<h2 id=\"构建鸟分类器\"><a href=\"#构建鸟分类器\" class=\"headerlink\" title=\"构建鸟分类器\"></a>构建鸟分类器</h2><p>如今我们已经足以写出一个程序来判断一张图上是不是鸟类。一如既往，我们需要训练数据来开始。免费的<a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR10数据集</a>包括了60,000张鸟类图片和52,000张非鸟图片。如果要更多的数据，我们还需要加入<a href=\"http://www.vision.caltech.edu/visipedia/CUB-200-2011.html\">Caltech-UCSD Birds-200-2011</a>数据集，内含12,000张鸟类图片。</p>\n<p>这是组合数据集的一部分鸟图：</p>\n<p><img src=\"/img/funny_machine/10045.png\"></p>\n<p>以及一部分非鸟图：</p>\n<p><img src=\"/img/funny_machine/10046.png\"></p>\n<p>这一数据集可以很好地满足我们的需求，不过相对于真实世界的应用而言，72,000张低分辨率图片还是太少，如果你想要达到Google级的水平，你需要上百万张高清无码大图。在机器学习中，数据多总是比算法好更重要。现在你就知道Google为什么那么乐意提供无限照片存储了，他们要的是你的数据啊，数据！</p>\n<blockquote>\n<p>原作者使用的是TFLearn，译注者改用了国内更流行的Keras。TFLearn代码可见作者原文。</p>\n</blockquote>\n<p>Keras封装了TensorFlow和Theano两个深度学习库并提供了简单易用的API，这使得开发者可以仅用几行就搭建一个卷积神经网络。</p>\n<p>以下是定义并训练网络的代码：</p>\n<p><strong>导入数据</strong></p>\n<p>Keras内置了CIFAR10数据集，但是需要从网络上下载。</p>\n<p>Keras导入CIFAR10数据集:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入相关库</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.misc <span class=\"keyword\">import</span> toimage</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.models <span class=\"keyword\">import</span> Sequential</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dense</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Dropout</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers <span class=\"keyword\">import</span> Flatten</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.constraints <span class=\"keyword\">import</span> maxnorm</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.optimizers <span class=\"keyword\">import</span> SGD</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers.convolutional <span class=\"keyword\">import</span> Convolution2D</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.layers.convolutional <span class=\"keyword\">import</span> MaxPooling2D</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras.utils <span class=\"keyword\">import</span> np_utils</span><br><span class=\"line\"><span class=\"keyword\">from</span> keras <span class=\"keyword\">import</span> backend <span class=\"keyword\">as</span> K</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义训练集、测试集</span></span><br><span class=\"line\">(X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Datasets is ready!&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预览部分图片</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">9</span>):</span><br><span class=\"line\">    pyplot.subplot(<span class=\"number\">330</span> + <span class=\"number\">1</span> + i)</span><br><span class=\"line\">    pyplot.imshow(toimage(X_train[i]))</span><br><span class=\"line\"></span><br><span class=\"line\">pyplot.show()</span><br></pre></td></tr></table></figure>\n\n<p><strong>搭建神经网络</strong></p>\n<p>下面导入其他将会用到的Keras相关模块并对数据进行预处理。Keras搭建神经网络的过程其实非常简单直观，就像搭积木一样。</p>\n<p>首先确定网络的基本结构，这里就用最基本<code>Sequential()</code>串型拓扑，并建立网络模型对象<code>model</code>。</p>\n<p>之后便是给<code>model</code>中一层层地添加网络，添加的方式也很简单，就是使用<code>model.add()</code>方法，逐个地把卷积层(<code>Convolution2D</code>)、池化层(<code>MaxPooling2D</code>)、全连接层(<code>Dense</code>)等插入到model里，形成整个神经网络。</p>\n<p>Keras搭建神经网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 对标签进行独热码编码</span></span><br><span class=\"line\">y_train = np_utils.to_categorical(y_train)</span><br><span class=\"line\">y_test = np_utils.to_categorical(y_test)</span><br><span class=\"line\">num_classes = y_test.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置神经网络对象model</span></span><br><span class=\"line\">model = Sequential()</span><br><span class=\"line\">model.add(Convolution2D(<span class=\"number\">32</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>,input_shape=(<span class=\"number\">32</span>,<span class=\"number\">32</span>,<span class=\"number\">3</span>),</span><br><span class=\"line\">                        border_mode=<span class=\"string\">&#x27;same&#x27;</span>,activation=<span class=\"string\">&#x27;relu&#x27;</span>,</span><br><span class=\"line\">                        W_constraint=maxnorm(<span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(Dropout(<span class=\"number\">0.2</span>))</span><br><span class=\"line\">model.add(Convolution2D(<span class=\"number\">32</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>,activation=<span class=\"string\">&#x27;relu&#x27;</span>,</span><br><span class=\"line\">                    border_mode=<span class=\"string\">&#x27;same&#x27;</span>,W_constraint=maxnorm(<span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(MaxPooling2D(pool_size=(<span class=\"number\">2</span>,<span class=\"number\">2</span>)))</span><br><span class=\"line\">model.add(Flatten())</span><br><span class=\"line\">model.add(Dense(<span class=\"number\">512</span>,activation=<span class=\"string\">&#x27;relu&#x27;</span>,W_constraint=maxnorm(<span class=\"number\">3</span>)))</span><br><span class=\"line\">model.add(Dropout(<span class=\"number\">0.5</span>))</span><br><span class=\"line\">model.add(Dense(num_classes,activation=<span class=\"string\">&#x27;softmax&#x27;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Neural Network built!&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>编译、训练、预测</strong></p>\n<p>经过以上过程，我们已经有了一个神经网络的外壳，但也仅仅是外壳，你会注意到上面这个代码模块运行的很快，因为这只是根据神经网络的设置形成了一个容器，内部还是空空如也。还要经过“编译”并且导入数据进行“训练”，我们才真正拥有了“有血有肉”的神经网络。最后通过与测试集的对比，衡量神经网络的表现。</p>\n<p>虽然数据量并不大，但是训练神经网络对于普通CPU来说，还是个比较艰巨的任务，因此训练速度可能堪忧。我们的网站后台暂时还未提供GPU接口，所以这里只能先将训练迭代次数设为1，以后我们会争取提供更强大的计算资源。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 设定训练过程</span></span><br><span class=\"line\">epoches = <span class=\"number\">1</span>  <span class=\"comment\"># 对训练集的迭代次数（这里设为最小的1）</span></span><br><span class=\"line\">lrate = <span class=\"number\">0.01</span> <span class=\"comment\"># 初始学习率</span></span><br><span class=\"line\">decay = lrate/epoches</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 优化器设置与编译</span></span><br><span class=\"line\">sgd = SGD(lr=lrate, momentum=<span class=\"number\">0.9</span>, decay=decay, nesterov=<span class=\"literal\">False</span>)</span><br><span class=\"line\">model.<span class=\"built_in\">compile</span>(loss=<span class=\"string\">&#x27;categorical_crossentropy&#x27;</span>,optimizer=sgd,metrics=[<span class=\"string\">&#x27;accuracy&#x27;</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.summary())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 用训练集数据训练网络</span></span><br><span class=\"line\">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epoches,</span><br><span class=\"line\">          batch_size=<span class=\"number\">32</span>, verbose=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输出神经网络的表现</span></span><br><span class=\"line\">scores = model.evaluate(X_test, y_test, verbose=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Accuracy: %.2f%%&quot;</span>) % (scores[<span class=\"number\">1</span>]*<span class=\"number\">100</span>)</span><br></pre></td></tr></table></figure>\n\n<p>如果你有个不错的显卡和足够的显存（比如Nvidia GeForce GTX 980 Ti或以上），大概一个小时可以训练完，如果用CPU的话可能就要久的多了。</p>\n<p>精度随着训练进程儿上升。第一轮过后，我的精度只有75.4%；经过十轮，精度已经提高到91.7%；在50轮以后，精度攀升到95.5%，再训练已经收效甚微了，因此我就此打住。</p>\n<p>Congrats!现在我们的程序可以识别图片里的鸟了！</p>\n<hr>\n<h2 id=\"测试网络\"><a href=\"#测试网络\" class=\"headerlink\" title=\"测试网络\"></a>测试网络</h2><p>有了训练过的神经网络，是骡子是马该拉出来遛遛。<a href=\"https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0\">这一简单的脚本</a>读取一个图片文件并判断是否是鸟。</p>\n<p>为了真正检验我们的神经网络是否有效，需要测试大批的图片。我这里用了15,000张图片作为验证集，当我把这15,000张图传递给神经网络，95%都得到了正确答案。</p>\n<p>听起来很好，对吧？其实这可未必！</p>\n<p><strong>95%是多准确？</strong></p>\n<p>我们的神经网络号称有95%的准确度，但是细微之处见真章，面子上95%，里子可能千差万别。比如说，如果我们的训练图片里5%是鸟，而另外95%不是鸟，然后一个程序只输出“不是鸟”就可以达到95%的精度，但这毫无意义。</p>\n<p>我们需要进一步细究这个数字，而不是满足于一个含糊的95%。为了判断一个分类系统的作用究竟几何，我们需要考察它是如何失效的，而不是失效的百分比。抛掉单纯的“对／错”标准，我们来把问题细分为四种分别的情况——</p>\n<ol>\n<li>把鸟正确地识别为鸟：<strong>True Positives</strong></li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10047.png\" alt=\"我们的网络成功地认出了很多不同的鸟类！\"></p>\n<ol start=\"2\">\n<li>把不是鸟的正确地排除出去：<strong>True Negatives</strong></li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10048.png\" alt=\"马和卡车糊弄不了我们\"></p>\n<ol start=\"3\">\n<li>以为是鸟，结果不是：<strong>False Positives</strong>（错杀三千）</li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10049.png\" alt=\"有些飞机也被当成鸟了\"></p>\n<ol start=\"4\">\n<li>其实是鸟，以为不是：<strong>False Negative</strong>（放过一个）</li>\n</ol>\n<p>  <img src=\"/img/funny_machine/10050.png\" alt=\"这些鸟把我们糊弄了\"></p>\n<p>根据我们这15,000张图片，以下为各种情况的统计数据：</p>\n<p><img src=\"/img/funny_machine/10051.png\"></p>\n<p>为什么要这样细分结果呢？因为并非每种错误都是均等的。想象一下，如果我们在写一个根据MRI图像诊断癌症的程序，这时候宁可引入<strong>False Positive</strong>也不要带有<strong>False Negative</strong>。前者只是让患者虚惊一场，后者可就是延误治疗了。</p>\n<p>所以出了宽泛的准确度，我们还计算<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">精确率和召回率</a>。精确率和召回率更加清晰地定义了分类起的效用。</p>\n<p><img src=\"/img/funny_machine/10052.png\"></p>\n<p>由上表可知，当我们给出“是鸟”的猜测时，其中97%是对的。但是我们却只找出了90%的鸟，这意味着我们可能不是所有鸟都认得，但是认鸟却很准！</p>\n","categories":[{"name":"学习记录","path":"api/categories/学习记录.json"},{"name":"机器学习","path":"api/categories/机器学习.json"}],"tags":[{"name":"机器学习","path":"api/tags/机器学习.json"}]}