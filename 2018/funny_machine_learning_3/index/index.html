<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>《机器学习有意思！ 03》- 深度学习与卷积神经网络 | 南山结庐</title><meta name="author" content="东篱先生"><meta name="copyright" content="东篱先生"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="《机器学习有意思！ 03》- 深度学习与卷积神经网络  原文：Machine Learning is Fun! Part 3 – Deep Learning and Convolutional Neural Networks 作者：Adam Geitgey   你是否厌倦了每天被深度学习相关的新闻轰炸却不明所以？此诚求变之机。 这一次我们将学习如何用深度学习来写程序识别图像中的物体。也可以说我们是">
<meta property="og:type" content="article">
<meta property="og:title" content="《机器学习有意思！ 03》- 深度学习与卷积神经网络">
<meta property="og:url" content="https://www.buerya.cn/2018/funny_machine_learning_3/index/index.html">
<meta property="og:site_name" content="南山结庐">
<meta property="og:description" content="《机器学习有意思！ 03》- 深度学习与卷积神经网络  原文：Machine Learning is Fun! Part 3 – Deep Learning and Convolutional Neural Networks 作者：Adam Geitgey   你是否厌倦了每天被深度学习相关的新闻轰炸却不明所以？此诚求变之机。 这一次我们将学习如何用深度学习来写程序识别图像中的物体。也可以说我们是">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.buerya.cn/img/avatar.png">
<meta property="article:published_time" content="2018-01-13T04:11:00.000Z">
<meta property="article:modified_time" content="2022-10-19T14:40:00.250Z">
<meta property="article:author" content="东篱先生">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.buerya.cn/img/avatar.png"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://www.buerya.cn/2018/funny_machine_learning_3/index/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="ar7mIVYsjkAi2k9jIuWk34S9A2aVwBdQqFkfL4AKEBQ"/><meta name="qihu_site_verification" content="d182b3f28525f2db83acfaaf6e696dba"/><meta name="baidu-site-verification" content="code-HKm4Y74Eag"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?2f0991ea306cfd77733ccdc8fddcf43c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '《机器学习有意思！ 03》- 深度学习与卷积神经网络',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-10-19 22:40:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/assets/fonts/font.css"> <link rel="stylesheet" href="/assets/css/import_style.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="南山结庐" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">95</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">60</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-table-list"></i><span> 归档</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-cubes"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><span> 空间</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/memos/"><i class="fa-fw fa fa-cloud-rain"></i><span> 说说</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><span> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('https://p2.ssl.qhimg.com/bdr/__85/t0123d36a2655435cb9.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="南山结庐"><span class="site-name">南山结庐</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-table-list"></i><span> 归档</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-cubes"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><span> 空间</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/memos/"><i class="fa-fw fa fa-cloud-rain"></i><span> 说说</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><span> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">《机器学习有意思！ 03》- 深度学习与卷积神经网络</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-01-13T04:11:00.000Z" title="发表于 2018-01-13 12:11:00">2018-01-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-10-19T14:40:00.250Z" title="更新于 2022-10-19 22:40:00">2022-10-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">学习记录</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>15分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="《机器学习有意思！ 03》- 深度学习与卷积神经网络"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="《机器学习有意思！-03》-深度学习与卷积神经网络"><a href="#《机器学习有意思！-03》-深度学习与卷积神经网络" class="headerlink" title="《机器学习有意思！ 03》- 深度学习与卷积神经网络"></a>《机器学习有意思！ 03》- 深度学习与卷积神经网络</h1><blockquote>
<p> <em>原文：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.8owg5e1ri">Machine Learning is Fun! Part 3 – Deep Learning and Convolutional Neural Networks</a></em><br> <em>作者：Adam Geitgey</em></p>
</blockquote>
<hr>
<p>你是否厌倦了每天被深度学习相关的新闻轰炸却不明所以？此诚求变之机。</p>
<p>这一次我们将学习如何用深度学习来写程序识别图像中的物体。也可以说我们是要解释Google图片搜索背后的黑科技：Google可以通过描述搜索图片——即使图片没有事先打上标签！这是如何实现的？</p>
<p>就像<a target="_blank" rel="noopener external nofollow noreferrer" href="http://blog.buerya.cn/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018-01-09-funny_machine_learning_1.html">Part 1</a>和<a target="_blank" rel="noopener external nofollow noreferrer" href="http://blog.buerya.cn/posts/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018-01-12-funny_machine_learning_2.html">Part 2</a>一样，本指南仍然面向所有对机器学习感兴趣却不知如何开始的朋友们。我们的目标是所有人都读得懂——因而势必无法照顾到每个细节。但那又如何呢？只要能让一位读者对ML感兴趣，那就是功德一件了！</p>
<hr>
<h2 id="深度学习识别物体"><a href="#深度学习识别物体" class="headerlink" title="深度学习识别物体"></a>深度学习识别物体</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10030.png"></p>
<blockquote>
<p>产品：每当一名用户拍了照片，APP应该检测他们是否在国家公园……</p>
</blockquote>
<blockquote>
<p>开发：当然了，不过是简单的GIS查询而已，给我几个小时。</p>
</blockquote>
<blockquote>
<p>产品：……以及拍的是不是一只鸟。</p>
</blockquote>
<blockquote>
<p>开发：那我需要一个研究小组和五年时间。</p>
</blockquote>
<blockquote>
<p>旁白：在计算机科学中，有时很难解释“简单”和“根本不可能”之间的区别。</p>
</blockquote>
<p>你可能已经在<a target="_blank" rel="noopener external nofollow noreferrer" href="https://xkcd.com/1425/">xkcd</a>系列漫画中看到过了。</p>
<p>这里的笑点在于，三岁小孩儿都能认出鸟的照片，但是教会计算机识别物体，已经让最优秀的计算机科学家耗费了50年。</p>
<p>在过去的几年里，我们终于找到了物体识别的好路子，那就是深度卷积神经网络。这听起来像是从威廉·吉布森的科幻小说里捡了几个词拼起来的，不过只要分解开来细看，其原理真的很简单。</p>
<p>开始吧——现在就写一个能认识鸟的程序！</p>
<hr>
<h2 id="始于足下"><a href="#始于足下" class="headerlink" title="始于足下"></a>始于足下</h2><p>在我们学习如何辨别鸟的照片之前，先来学个简单得多的例子——手写数字”8”。</p>
<p>在Part 2中，我们已经学习了神经网络如何链接大量的神经元来解决复杂问题。我们搭建了一个迷你神经网络来基于房间数、面积、周边环境预测房价：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10031.png"></p>
<p>我们还知道了机器学习的思想就是重复利用相同的普适算法，根据不同的数据，解决不同的问题。下面我们修改这个神经网络来识别手写文本，并且进一步简化任务——只识别数字”8”。</p>
<p>机器学习只有当你有数据的时候才好使——数据越多越好，所以我们需要大量的手写”8”来开始。所幸，研究者们为了这一目的已经建立了<a target="_blank" rel="noopener external nofollow noreferrer" href="http://yann.lecun.com/exdb/mnist/">MNIST手写数字数据集</a>。<code>MNIST</code>提供了60,000张手写数字的图片，每个尺寸都是18x18，以下是数据集里部分的”8”：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10032.jpeg" alt="MNIST数据集里的一些8"></p>
<p><strong>其实不过是数字</strong></p>
<p>Part 2里搭建的神经网络只读取3个输入（”3”间卧室,”2000”平方米等）。但是现在我们要用神经网络处理图片，不是数字怎么传入神经网络呢？</p>
<p>答案无比的简单。神经网络以数字为输入，对于计算机来说，图片也不过只是代表了像素明暗的数字：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10030.gif"></p>
<p>只要把18x18像素的图片当作324个数字组成的数组，就可以把图片输入给神经网络了。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10032.png"></p>
<p>要处理324个输入，我们只需让神经网络具有324个输入节点：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10033.png"></p>
<p>注意我们的神经网络现在有两个输出（而非之前的一个）。第一个输出是预测此图为”8”的概率，第二个为不是”8”的概率。每种类型的目标物体有了分别的输出，就可以让神经网络对物体进行分类了。</p>
<p>这次的神经网络比之前要大得多了（从3个输入到324），但是现代的计算机处理几百个节点的神经网络，连眼都不带眨的，甚至连手机都能轻松满足。</p>
<p>剩下的就是用”8”和非”8”的数字去训练神经网络以使其能够区分两者了，当我们输入一个”8”，我们告诉神经网络，此图为”8”的概率是100%，非”8”的概率是0%，反之亦反。</p>
<p>这是我们的训练数据：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10030.jpeg"></p>
<p>现在随便一个笔记本电脑，也能在几分钟之内训练完这样一个网络，训练完之后我们就拥有了能够高精度识别数字”8”的神经网络。欢迎来到（1980年代的）图像识别世界！</p>
<hr>
<h2 id="管窥"><a href="#管窥" class="headerlink" title="管窥"></a>管窥</h2><p>把像素简单地导入神经网络里一训练，就能识别图像了，感觉无比清爽。机器学习真乃魔法……也？</p>
<p><em>事情并不简单。</em></p>
<p>首先，一个好消息是，我们的识8器对于图片正中的数字，效果还是很喜人的：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10034.png"></p>
<p>现在坏消息来了：</p>
<p>当数字不是恰好居中的时候，识8器完全失效了，哪怕一丁点的位置偏差也不行：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10035.png"></p>
<p>这是因为，神经网络只学到了恰好居中”8”的模式，但是对于离心的”8”却一无所知，它知道且仅知道一种模式。</p>
<p>在现实中这就实用价值不大了，因为实际问题不可能总是那么干净简约。所以我们必须让神经网络能够处理离心的”8”。</p>
<h3 id="暴力方法-1-滑动窗口搜索"><a href="#暴力方法-1-滑动窗口搜索" class="headerlink" title="暴力方法 1. 滑动窗口搜索"></a>暴力方法 1. 滑动窗口搜索</h3><p>我们已经有了一个好方法，能够找到图片中心的”8”，那可不可以在图片上扫描寻找子区域里的”8”，直至找到呢？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10031.gif"></p>
<p>这就是滑动窗口法，一种非常暴力的解决方案。在很有限的某些例子中可行，但效率也很低。你必须一遍一遍地寻找不同尺寸的物体，我们可以比这更好。</p>
<h3 id="暴力方法-2-更多数据，更深网络"><a href="#暴力方法-2-更多数据，更深网络" class="headerlink" title="暴力方法 2. 更多数据，更深网络"></a>暴力方法 2. 更多数据，更深网络</h3><p>当我们在训练网络的时候，只用到了完美居中的”8”。如果我们在训练过程中就引入不同位置、不同大小的”8”，那会怎么样呢？</p>
<p>不需要收集更多的训练数据，我们可以写个脚本生成新的图片，图中的”8”具有不同的位置和大小：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10036.png" alt="用已有训练图片的不同视角制成的合成训练数据，这是个挺有用的技术"></p>
<p>应用这一技术，我们可以轻易创造出无穷多的训练数据。</p>
<p>更多的数据让问题变得更加复杂了，但是我们可以用更大的神经网络，那样就能学习更复杂的模式。为了扩大网络，我们简单地把节点层堆叠起来：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10037.png"></p>
<p>这就是“深度神经网络”，因为比传统神经网络的层数更多。这个想法在1960年代便有了，不过直至最近，训练这么大的神经网络训练还是慢得无法接受。但是自从我们发现了用3d显卡替代传统CPU来加速矩阵计算，大规模神经网络就变得可行了。你用来玩守望先锋的NVIDIA GeForce GTX 1080显卡，也可以用来训练神经网络。</p>
<p>然而即便我们可以用显卡很快地训练出大规模神经网络，这仍然不是解决方案的全部，我们还需要在处理图片上更加机智才行。</p>
<p>在暴力方法2中，把图片顶端的”8”和图片底部的”8”当作完全不同的物体，这其实是没有意义的。应该存在一种方案，让神经网络不经额外训练即知：图片不管哪个位置的”8”都是一个东西。万幸，确实是存在的！</p>
<hr>
<h2 id="答案：卷积"><a href="#答案：卷积" class="headerlink" title="答案：卷积"></a>答案：卷积</h2><p>生而为人，你可以直观地看出照片中含有层次或概念结构。考虑这张照片：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10031.jpeg" alt="作者儿子的照片"></p>
<p>作为一个人类，你立即就能识别出照片里的层次：</p>
<ul>
<li><p>地面覆盖了草坪</p>
</li>
<li><p>图里有个小孩儿</p>
</li>
<li><p>小孩儿骑在弹跳小马上</p>
</li>
<li><p>弹跳小马在草坪上</p>
</li>
</ul>
<p>更重要的是，无论小孩在什么样的表面上，我们都能认出那是个小孩儿。我们并不需要重新学习各种表面上的小孩儿。但是目前，神经网络还做不到这些，它会把不同位置的”8”当作完全不同的东西，而并不知道在图片上移动物体不会改变其实质。这意味着网络必须重新学习每个位置上的物体，太悲催了。</p>
<p>我们需要让神经网络明白平移不变形——“8”还是”8”，不论出现在图片的哪里。这一过程可由卷积实现，卷积的想法部分来自计算机科学，还有部分是受生物学启发（比如，疯狂科学家们真的在猫脑子里插管，以研究猫是怎么处理图像的人）。</p>
<hr>
<h2 id="卷积的作用机理"><a href="#卷积的作用机理" class="headerlink" title="卷积的作用机理"></a>卷积的作用机理</h2><p>这次我们不再把整个图片当成一个数字网格输入到神经网络，而是利用物体与位置的独立性，做得更聪明些。以下就是卷积的作用机理，一步一步来——</p>
<p><strong>第1步：把图片分解为重叠碎片</strong></p>
<p>与之前的滑动窗口法类似，这里也用一个窗口在整张原图上滑动截图，并且把截到的每一小部分单独存成一个图片：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10038.png"></p>
<p>如此我们便把一张大图拆成了77张等尺寸的小图。</p>
<p><strong>第2步：把每张小图输入小神经网络</strong></p>
<p>曾经我们把单张图片输入神经网络来判断其是否为”8”，这里再重复一样的工作，不过是针对每一个单独的小图片：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10039.png" alt="对每个小图片重复77次"></p>
<p>这里还有一大诀窍：我们将相同的<em>神经网络权重</em>应用在每一块小图上。换言之，我们平等地对待所有小图，如果某个小图里出现了我们感兴趣的内容，我们就将其标记为有趣。</p>
<p><strong>第3步：把每块小图的结果存入新的阵列</strong></p>
<p>我们并不想丢失原始小图的排列信息，所以我们要把每个小图的结果按照相同的排列重新构建原图，形式如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10040.png"></p>
<p>也可以说，我们从一张大图片开始，到小阵列结束，阵列记录了原图当中哪一部分有我们最关心的内容。</p>
<p><strong>第4步：下采样</strong></p>
<p>第3步的结果是一个阵列，反映了原图的哪一部分是我们最感兴趣的，不过这个阵列仍然很庞大：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10041.png"></p>
<p>为了减小阵列的尺寸，我们用<a target="_blank" rel="noopener external nofollow noreferrer" href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer">最大池化</a>算法进行下采样。听着很稀奇，其实完全不！</p>
<p>看阵列中的每个2x2方块，并且只留下最大的数字：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10042.png"></p>
<p>这里的主要思路就是，当我们在组成2x2方块的四个输入小图中的任意一个发现了关心的内容，就只保留我们最感兴趣的信息，这可以减小阵列规模并保留最重要的信息。</p>
<p><strong>最终步：预测</strong></p>
<p>至此，我们已经把一个巨大的图片消减成了相对较小的阵列，阵列就是一串数，所以我们可以把小阵列输入另一个神经网络，最后的这个神经网络会决定图片是否匹配。为了与卷积层相区分，我们称之为“全连接层”。从头到尾，我们的五步流水线如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10043.png"></p>
<p><strong>增加更多步骤</strong></p>
<p>我们的图像处理流水线有一系列步骤：卷积，最大池化，全连接网络。</p>
<p>而在解决实际问题的时候，这些步骤可以组合起来并堆叠多次。你可以加两个，三个甚至十个卷积层，也可以在任何时候插入一个最大池化层。总之基本思路就是把一张大图，逐步分解为小图，直至我们能够获得结果。卷积层越多，网络就能学习识别越复杂的特征。</p>
<p>比如说，第一个卷积层可能学会了辨认锐利边缘，第二个卷积层可能根据锐边的知识学会了识别鸟喙，第三个卷积层又基于鸟喙识别出了整只鸟。以下是更贴近实践的深度卷积网络结构（学术论文里常见）：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10044.png"></p>
<p>在这一实例中，他们从224x224像素的图片开始，应用了：卷积，两次最大池化，三次卷积，又是两次最大池化，最后是两个全连接层。最终的结果可以将图片从1000个分类中识别出来。</p>
<p><strong>构建正确的网络</strong></p>
<p>那么我们要怎么知道什么时候该用什么层呢？诚然，你得经过大量的实践和测试才能回答，可能训练100个网络才能找到最佳的结构和参数。机器学习就是包含了大量的尝试和错误！</p>
<h2 id="构建鸟分类器"><a href="#构建鸟分类器" class="headerlink" title="构建鸟分类器"></a>构建鸟分类器</h2><p>如今我们已经足以写出一个程序来判断一张图上是不是鸟类。一如既往，我们需要训练数据来开始。免费的<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10数据集</a>包括了60,000张鸟类图片和52,000张非鸟图片。如果要更多的数据，我们还需要加入<a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html">Caltech-UCSD Birds-200-2011</a>数据集，内含12,000张鸟类图片。</p>
<p>这是组合数据集的一部分鸟图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10045.png"></p>
<p>以及一部分非鸟图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10046.png"></p>
<p>这一数据集可以很好地满足我们的需求，不过相对于真实世界的应用而言，72,000张低分辨率图片还是太少，如果你想要达到Google级的水平，你需要上百万张高清无码大图。在机器学习中，数据多总是比算法好更重要。现在你就知道Google为什么那么乐意提供无限照片存储了，他们要的是你的数据啊，数据！</p>
<blockquote>
<p>原作者使用的是TFLearn，译注者改用了国内更流行的Keras。TFLearn代码可见作者原文。</p>
</blockquote>
<p>Keras封装了TensorFlow和Theano两个深度学习库并提供了简单易用的API，这使得开发者可以仅用几行就搭建一个卷积神经网络。</p>
<p>以下是定义并训练网络的代码：</p>
<p><strong>导入数据</strong></p>
<p>Keras内置了CIFAR10数据集，但是需要从网络上下载。</p>
<p>Keras导入CIFAR10数据集:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相关库</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</span><br><span class="line"><span class="keyword">from</span> keras.constraints <span class="keyword">import</span> maxnorm</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练集、测试集</span></span><br><span class="line">(X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Datasets is ready!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预览部分图片</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">    pyplot.subplot(<span class="number">330</span> + <span class="number">1</span> + i)</span><br><span class="line">    pyplot.imshow(toimage(X_train[i]))</span><br><span class="line"></span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>

<p><strong>搭建神经网络</strong></p>
<p>下面导入其他将会用到的Keras相关模块并对数据进行预处理。Keras搭建神经网络的过程其实非常简单直观，就像搭积木一样。</p>
<p>首先确定网络的基本结构，这里就用最基本<code>Sequential()</code>串型拓扑，并建立网络模型对象<code>model</code>。</p>
<p>之后便是给<code>model</code>中一层层地添加网络，添加的方式也很简单，就是使用<code>model.add()</code>方法，逐个地把卷积层(<code>Convolution2D</code>)、池化层(<code>MaxPooling2D</code>)、全连接层(<code>Dense</code>)等插入到model里，形成整个神经网络。</p>
<p>Keras搭建神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对标签进行独热码编码</span></span><br><span class="line">y_train = np_utils.to_categorical(y_train)</span><br><span class="line">y_test = np_utils.to_categorical(y_test)</span><br><span class="line">num_classes = y_test.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置神经网络对象model</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Convolution2D(<span class="number">32</span>,<span class="number">3</span>,<span class="number">3</span>,input_shape=(<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>),</span><br><span class="line">                        border_mode=<span class="string">&#x27;same&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                        W_constraint=maxnorm(<span class="number">3</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">model.add(Convolution2D(<span class="number">32</span>,<span class="number">3</span>,<span class="number">3</span>,activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                    border_mode=<span class="string">&#x27;same&#x27;</span>,W_constraint=maxnorm(<span class="number">3</span>)))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>,W_constraint=maxnorm(<span class="number">3</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(num_classes,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Neural Network built!&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>编译、训练、预测</strong></p>
<p>经过以上过程，我们已经有了一个神经网络的外壳，但也仅仅是外壳，你会注意到上面这个代码模块运行的很快，因为这只是根据神经网络的设置形成了一个容器，内部还是空空如也。还要经过“编译”并且导入数据进行“训练”，我们才真正拥有了“有血有肉”的神经网络。最后通过与测试集的对比，衡量神经网络的表现。</p>
<p>虽然数据量并不大，但是训练神经网络对于普通CPU来说，还是个比较艰巨的任务，因此训练速度可能堪忧。我们的网站后台暂时还未提供GPU接口，所以这里只能先将训练迭代次数设为1，以后我们会争取提供更强大的计算资源。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设定训练过程</span></span><br><span class="line">epoches = <span class="number">1</span>  <span class="comment"># 对训练集的迭代次数（这里设为最小的1）</span></span><br><span class="line">lrate = <span class="number">0.01</span> <span class="comment"># 初始学习率</span></span><br><span class="line">decay = lrate/epoches</span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器设置与编译</span></span><br><span class="line">sgd = SGD(lr=lrate, momentum=<span class="number">0.9</span>, decay=decay, nesterov=<span class="literal">False</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,optimizer=sgd,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用训练集数据训练网络</span></span><br><span class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epoches,</span><br><span class="line">          batch_size=<span class="number">32</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出神经网络的表现</span></span><br><span class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accuracy: %.2f%%&quot;</span>) % (scores[<span class="number">1</span>]*<span class="number">100</span>)</span><br></pre></td></tr></table></figure>

<p>如果你有个不错的显卡和足够的显存（比如Nvidia GeForce GTX 980 Ti或以上），大概一个小时可以训练完，如果用CPU的话可能就要久的多了。</p>
<p>精度随着训练进程儿上升。第一轮过后，我的精度只有75.4%；经过十轮，精度已经提高到91.7%；在50轮以后，精度攀升到95.5%，再训练已经收效甚微了，因此我就此打住。</p>
<p>Congrats!现在我们的程序可以识别图片里的鸟了！</p>
<hr>
<h2 id="测试网络"><a href="#测试网络" class="headerlink" title="测试网络"></a>测试网络</h2><p>有了训练过的神经网络，是骡子是马该拉出来遛遛。<a target="_blank" rel="noopener external nofollow noreferrer" href="https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0">这一简单的脚本</a>读取一个图片文件并判断是否是鸟。</p>
<p>为了真正检验我们的神经网络是否有效，需要测试大批的图片。我这里用了15,000张图片作为验证集，当我把这15,000张图传递给神经网络，95%都得到了正确答案。</p>
<p>听起来很好，对吧？其实这可未必！</p>
<p><strong>95%是多准确？</strong></p>
<p>我们的神经网络号称有95%的准确度，但是细微之处见真章，面子上95%，里子可能千差万别。比如说，如果我们的训练图片里5%是鸟，而另外95%不是鸟，然后一个程序只输出“不是鸟”就可以达到95%的精度，但这毫无意义。</p>
<p>我们需要进一步细究这个数字，而不是满足于一个含糊的95%。为了判断一个分类系统的作用究竟几何，我们需要考察它是如何失效的，而不是失效的百分比。抛掉单纯的“对／错”标准，我们来把问题细分为四种分别的情况——</p>
<ol>
<li>把鸟正确地识别为鸟：<strong>True Positives</strong></li>
</ol>
<p>  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10047.png" alt="我们的网络成功地认出了很多不同的鸟类！"></p>
<ol start="2">
<li>把不是鸟的正确地排除出去：<strong>True Negatives</strong></li>
</ol>
<p>  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10048.png" alt="马和卡车糊弄不了我们"></p>
<ol start="3">
<li>以为是鸟，结果不是：<strong>False Positives</strong>（错杀三千）</li>
</ol>
<p>  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10049.png" alt="有些飞机也被当成鸟了"></p>
<ol start="4">
<li>其实是鸟，以为不是：<strong>False Negative</strong>（放过一个）</li>
</ol>
<p>  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10050.png" alt="这些鸟把我们糊弄了"></p>
<p>根据我们这15,000张图片，以下为各种情况的统计数据：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10051.png"></p>
<p>为什么要这样细分结果呢？因为并非每种错误都是均等的。想象一下，如果我们在写一个根据MRI图像诊断癌症的程序，这时候宁可引入<strong>False Positive</strong>也不要带有<strong>False Negative</strong>。前者只是让患者虚惊一场，后者可就是延误治疗了。</p>
<p>所以出了宽泛的准确度，我们还计算<a target="_blank" rel="noopener external nofollow noreferrer" href="https://en.wikipedia.org/wiki/Precision_and_recall">精确率和召回率</a>。精确率和召回率更加清晰地定义了分类起的效用。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/funny_machine/10052.png"></p>
<p>由上表可知，当我们给出“是鸟”的猜测时，其中97%是对的。但是我们却只找出了90%的鸟，这意味着我们可能不是所有鸟都认得，但是认鸟却很准！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://www.buerya.cn">东篱先生</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.buerya.cn/2018/funny_machine_learning_3/index/">https://www.buerya.cn/2018/funny_machine_learning_3/index/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.buerya.cn" target="_blank">南山结庐</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/learnblockchain/index/" title="如何学习区块链"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">如何学习区块链</div></div></a></div><div class="next-post pull-right"><a href="/2018/funny_machine_learning_2/index/" title="《机器学习有意思！ 02》- 使用机器学习生成超级玛丽关卡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">《机器学习有意思！ 02》- 使用机器学习生成超级玛丽关卡</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2018/funny_machine_learning_1/index/" title="《机器学习有意思！ 01》- 世界上最简单的机器学习入门"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-09</div><div class="title">《机器学习有意思！ 01》- 世界上最简单的机器学习入门</div></div></a></div><div><a href="/2018/funny_machine_learning_2/index/" title="《机器学习有意思！ 02》- 使用机器学习生成超级玛丽关卡"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-01-12</div><div class="title">《机器学习有意思！ 02》- 使用机器学习生成超级玛丽关卡</div></div></a></div><div><a href="/2017/machine_learning_base/index/" title="【机器学习】先搞懂这八大基础概念，再谈机器学习入门"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2017-11-29</div><div class="title">【机器学习】先搞懂这八大基础概念，再谈机器学习入门</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">东篱先生</div><div class="author-info__description">宁愿花时间去修炼不完美的自己&#44;也不要浪费时间去期待完美的别人。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">95</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">60</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/quewen08"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:trover@foxmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fa fa-envelope" style="color: #24292e;"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="Atom"><i class="fa fa-rss" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">新的一年，感謝訪問本站，若喜歡請收藏 ^_^</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%89%E6%84%8F%E6%80%9D%EF%BC%81-03%E3%80%8B-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">《机器学习有意思！ 03》- 深度学习与卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%86%E5%88%AB%E7%89%A9%E4%BD%93"><span class="toc-number">1.1.</span> <span class="toc-text">深度学习识别物体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A7%8B%E4%BA%8E%E8%B6%B3%E4%B8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">始于足下</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%A1%E7%AA%A5"><span class="toc-number">1.3.</span> <span class="toc-text">管窥</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9A%B4%E5%8A%9B%E6%96%B9%E6%B3%95-1-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%90%9C%E7%B4%A2"><span class="toc-number">1.3.1.</span> <span class="toc-text">暴力方法 1. 滑动窗口搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9A%B4%E5%8A%9B%E6%96%B9%E6%B3%95-2-%E6%9B%B4%E5%A4%9A%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%9B%B4%E6%B7%B1%E7%BD%91%E7%BB%9C"><span class="toc-number">1.3.2.</span> <span class="toc-text">暴力方法 2. 更多数据，更深网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AD%94%E6%A1%88%EF%BC%9A%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.4.</span> <span class="toc-text">答案：卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8%E6%9C%BA%E7%90%86"><span class="toc-number">1.5.</span> <span class="toc-text">卷积的作用机理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E9%B8%9F%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">1.6.</span> <span class="toc-text">构建鸟分类器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C"><span class="toc-number">1.7.</span> <span class="toc-text">测试网络</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/docker-network/index/" title="网络管理"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/2022/about-docker/979767-20220608220537883-1025728940.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="网络管理"/></a><div class="content"><a class="title" href="/2022/docker-network/index/" title="网络管理">网络管理</a><time datetime="2022-10-21T12:11:19.000Z" title="发表于 2022-10-21 20:11:19">2022-10-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/docker-assets/index/" title="资源限制"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/2022/about-docker/979767-20220608220537883-1025728940.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="资源限制"/></a><div class="content"><a class="title" href="/2022/docker-assets/index/" title="资源限制">资源限制</a><time datetime="2022-10-20T13:39:39.000Z" title="发表于 2022-10-20 21:39:39">2022-10-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/docker-volume/index/" title="数据持久化"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/2022/about-docker/979767-20220608220537883-1025728940.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据持久化"/></a><div class="content"><a class="title" href="/2022/docker-volume/index/" title="数据持久化">数据持久化</a><time datetime="2022-09-21T13:39:39.000Z" title="发表于 2022-09-21 21:39:39">2022-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/docker-image/index/" title="镜像制作"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/2022/about-docker/979767-20220608220537883-1025728940.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="镜像制作"/></a><div class="content"><a class="title" href="/2022/docker-image/index/" title="镜像制作">镜像制作</a><time datetime="2022-08-20T13:29:39.000Z" title="发表于 2022-08-20 21:29:39">2022-08-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/docker-container/index/" title="容器管理"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/2022/about-docker/979767-20220608220537883-1025728940.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="容器管理"/></a><div class="content"><a class="title" href="/2022/docker-container/index/" title="容器管理">容器管理</a><time datetime="2022-07-19T13:29:39.000Z" title="发表于 2022-07-19 21:29:39">2022-07-19</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2017 - 2023 By 东篱先生</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener external nofollow noreferrer" href="http://buerya.cn/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'LoojPRMy175IgqwnQtytrgOY-9Nh9j0Va',
      appKey: '45VXhysB6in2v1IOL1kaC5tQ',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script data-pjax src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/echarts/5.3.0-rc.1/echarts.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>